{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bits per Symbol\n",
    "k = 4\n",
    "\n",
    "# Number of symbols\n",
    "\n",
    "L = 50\n",
    "# Channel Use\n",
    "n = 3\n",
    "\n",
    "# Effective Throughput\n",
    "#  (bits per symbol)*( number of symbols) / channel use\n",
    "R = k / n\n",
    "\n",
    "# Eb/N0 used for training\n",
    "train_Eb_dB = 12\n",
    "\n",
    "# Noise Standard Deviation\n",
    "noise_sigma = np.sqrt(1 / (2 * R * 10 ** (train_Eb_dB / 10)))\n",
    "\n",
    "# Number of messages used for training, each size = k*L\n",
    "batch_size = 64\n",
    "nb_train_word = batch_size*k*L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the binary sequence and converting to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12800, 200), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 1, ..., 1, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Binary Sequence\n",
    "train_data = tf.random.uniform(shape=(nb_train_word, k*L), minval=0, maxval=2, dtype=tf.dtypes.int32)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12800, 50, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping into N x L x k (N: number of data messages, L: block length, k: bits/symbol)\n",
    "train_data = tf.reshape(shape=(nb_train_word, L, k), tensor=train_data)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integers samples Shape: (12800, 50, 1)\n",
      "One-Hot TRAINING Shape: (12800, 50, 16)\n"
     ]
    }
   ],
   "source": [
    "def BitsToInt(bits, k):\n",
    "    '''Function to transform a binary sequence into integers.'''\n",
    "    a = 2**np.arange(k)[::-1]\n",
    "    a = np.reshape(a, newshape=(k,1))\n",
    "    return bits @ a\n",
    "\n",
    "tmp = BitsToInt(train_data.numpy(),k)\n",
    "print('Integers samples Shape:', tmp.shape)\n",
    "one_hot_train = tf.keras.utils.to_categorical(y=tmp, num_classes=2 ** k)\n",
    "print('One-Hot TRAINING Shape:', one_hot_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot LABELS Shape: (12800, 50, 16)\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels = tf.identity(one_hot_train)\n",
    "print('One-Hot LABELS Shape:', one_hot_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_patience = 100\n",
    "\n",
    "epochs = 250\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                               patience=early_stopping_patience)\n",
    "\n",
    "\n",
    "# Learning Rate Control\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1,\n",
    "                              patience=5, min_lr=0.0001)\n",
    "\n",
    "# Save the best results based on Training Set\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath='./' + 'model_' + str(k) + '_' + str(L) + '_' + str(n) + '_' + str(train_Eb_dB) + 'dB' + ' ' + 'Rayleigh ' + '.h5',\n",
    "                                  monitor='loss',\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  save_weights_only=True,\n",
    "                                  mode='auto', save_freq=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
